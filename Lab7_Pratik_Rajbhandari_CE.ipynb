{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab7_Pratik_Rajbhandari_CE.ipynb","provenance":[],"authorship_tag":"ABX9TyNsp/TFsK2M4fcZR2B+yzLA"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"FhTTbphF4k78","colab_type":"text"},"source":["# Creating an Environment"]},{"cell_type":"code","metadata":{"id":"VBeXNoQd4p7r","colab_type":"code","colab":{}},"source":["  \n","import argparse\n","\n","import gym\n","\n","def build_arg_parser():\n","    parser = argparse.ArgumentParser(description='Run an environment')\n","    parser.add_argument('--input-env', dest='input_env', required=True,\n","            choices=['cartpole', 'mountaincar', 'pendulum', 'taxi', 'lake'], \n","            help='Specify the name of the environment')\n","    return parser\n","\n","if __name__=='__main__':\n","    args = build_arg_parser().parse_args()\n","    input_env = args.input_env\n","\n","    name_map = {'cartpole': 'CartPole-v0', \n","                'mountaincar': 'MountainCar-v0',\n","                'pendulum': 'Pendulum-v0',\n","                'taxi': 'Taxi-v1',\n","                'lake': 'FrozenLake-v0'}\n","\n","    env = gym.make(name_map[input_env])\n","    env.reset()\n","\n","    for _ in range(1000):\n","        env.render()\n","\n","        env.step(env.action_space.sample()) "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5zwsWik0-yd5","colab_type":"text"},"source":["# Building a Learning Agent"]},{"cell_type":"code","metadata":{"id":"4T3nu8Y_-0J8","colab_type":"code","colab":{}},"source":["def build_arg_parser():\n","  parser = argparse.ArgumentParser(description='Run an environment')\n","  parser.add_argument('--input-env', dest='input_env', required=True,\n","  choices=['cartpole', 'mountaincar', 'pendulum'],\n","  help='Specify the name of the environment')\n","  return parser\n","\n","args = build_arg_parser().parse_args()\n","input_env = args.input_env\n","\n","name_map = {'cartpole': 'CartPole-v0',\n"," 'mountaincar': 'MountainCar-v0',\n"," 'pendulum': 'Pendulum-v0'}\n","\n","env = gym.make(name_map[input_env])\n","\n","for _ in range(20):\n","  observation = env.reset()\n","\n","for i in range(100):\n","  env.render()\n","\n","action = env.action_space.sample()\n","\n","if done:\n","  print('Episode finished after {} timesteps'.format(i+1))\n","  break"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h05Or4VV_m53","colab_type":"text"},"source":["# Example Code For Q-Learning"]},{"cell_type":"code","metadata":{"id":"wRKaRkzB_p-R","colab_type":"code","colab":{}},"source":["import numpy as np\n","import random\n","import matplotlib.pyplot as plt\n","from matplotlib.collections import LineCollection\n","\n","R = np.array([[-1, -1, -1, -1, 0, -1],\n"," [-1, -1, -1, 0, -1, 100],\n"," [-1, -1, -1, 0, -1, -1],\n"," [-1,0, 0, -1, 0, -1],\n"," [ 0, -1, -1, 0, -1, 100],\n"," [-1, 0, -1, -1, 0, 100]]).astype(\"float32\")\n","\n","Q = np.zeros_like(R)\n","gamma = 0.8\n","initial_state = random.randint(0,4)\n","\n","def available_actions(state):\n","  current_state_row = R[state,]\n","  av_act = np.where(current_state_row >= 0)[1]\n","  return av_act\n","\n","def sample_next_action(available_actions_range):\n","  next_action = int(np.random.choice(available_act,1))\n","  return next_action\n","\n","\n","def update(current_state, action, gamma):\n"," max_index = np.where(Q[action,] == np.max(Q[action,]))[1]\n"," \n"," if max_index.shape[0] > 1:\n","  max_index = int(np.random.choice(max_index, size = 1))\n"," else:\n","  max_index = int(max_index)\n"," max_value = Q[action, max_index]\n"," Q[current_state, action] = R[current_state, action] + gamma * max_value\n","\n","available_act = available_actions(initial_state)\n","action = sample_next_action(available_act)\n","\n","for i in range(100):\n"," current_state = np.random.randint(0, int(Q.shape[0]))\n"," available_act = available_actions(current_state)\n"," action = sample_next_action(available_act)\n"," update(current_state,action,gamma)\n","\n","print(\"Trained Q matrix: \\n\", Q/np.max(Q)*100)\n","\n","current_state = 2\n","steps = [current_state]\n","while current_state != 5:\n"," next_step_index = np.where(Q[current_state,] == np.max(Q[current_state,]))[1]\n"," if next_step_index.shape[0] > 1:\n","   next_step_index = int(np.random.choice(next_step_index, size = 1))\n"," else:\n","  next_step_index = int(next_step_index)\n"," steps.append(next_step_index)\n"," current_state = next_step_index\n","\n","print(\"Best sequence path: \", steps)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HoAB-VjFABV2","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}